# Architecture
arch: vit

# ===== Dataset ===== #
data: /mnt/disk1/datasets
set: ImageNet

# ===== Learning Rate Policy ======== #
optimizer: adam
lr: 1e-4
lr_policy: cosine_lr
warmup_length: 5

# ===== Network training config ===== #
epochs: 200
weight_decay: 0.000030517578125
momentum: 0.875
batch_size: 256

# ===== Sparsity =========== #
conv_type: SubnetConv
bn_type: NonAffineBatchNorm
freeze_weights: True
prune_rate: -1 # Override
init: kaiming_normal
mode: fan_in
nonlinearity: relu

# ===== Hardware setup ===== #
workers: 8